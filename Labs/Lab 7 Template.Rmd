---
title: "Lab 7 Template"
author: "Dustin Duncan"
date: "2024-03-01"
output: pdf_document
---


```{r, setup }
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
# install.packages("bmscstan") --> This package might be useful if you're getting errors
# library(bmscstan)
library(tidyverse)
library(rethinking)
library(bayesplot)
source("../helper.R")
```
# Bayesian Statistical Modeling Winter 2024
# Lab Exercise, Week 8


*When is this lab due?* Labs are due on the Thursday after they are assigned. However, in many cases you can complete them during the lab period itself.   This assignment is due on Thursday, 3/7/2022.  

## Load and process the data


Load the dataset. It contains Covid case numbers and deaths for all counties in California.
```{r }
load("SB_covid_data_2022.Rdata")
```


We're going to calculate some new columns that summarize weekly total Covid cases. To do this we need to group by the county, and make sure the data are in order by date. The column `delta.days` is the number of days elapsed since data on COVID cases were first reported last winter. 

```{r  }
county_ca <- group_by(county_ca,county) %>% # Grouping by county
  arrange(delta.days) %>% # Arranging delta.days in order of increasing value 
  mutate(new_cases = cases-lag(cases), # New cases is = cases (current) minus the previous value of cases
         week_cases=(cases-lag(cases,7))/7, # Weekly avg new cases = cases (current) minus the value from 7 days ago, divided by 7 
         week_old_cases=(lag(cases,7)-lag(cases,14))/7, # Avg number of cases over the previous 7 days by taking the value of cases from 7 days ago, subtracting the cases from 14 days ago, and dividing by 7
         two_week_old_cases=(lag(cases,14)-lag(cases,21))/7, # same as week_old but now 14 days 
         three_week_old_cases=(lag(cases,21)-lag(cases,28))/7, # so on...
         four_week_old_cases=(lag(cases,28)-lag(cases,35))/7, # so on... 
         new_deaths = deaths-lag(deaths)) %>% # number of new deaths = deaths (current) minus the previous value of deaths 
  ungroup()

```

We are now going to pull out the Santa Barbara county data, but only since day 100. We will also standardize our potential predictor variables. 
```{r }
firstday=101 # setting value to filter dataframe on
  
  sb_data<-filter(county_ca,delta.days>firstday,county == "Santa Barbara", state=="California")%>% 
  view()

```


## Check out the data

This draws a cubic spline fit through the 7-day average case number.
```{r, warning=FALSE}
firstday=101
maxday=800
ssvals <- smooth.spline(x=sb_data$delta.days, y= sb_data$week_cases, df=15)
spline_data <- tibble( delta.days=ssvals$x, week_cases = ssvals$y)
 

ggplot(data=sb_data, aes(x=delta.days,y= week_cases/7)) +
  geom_point()+
  geom_line(data=spline_data,color="red")+
  scale_y_continuous( limits=c(1,250) )+
  scale_x_continuous(limits=c(firstday,maxday))+
  labs( x="days since Jan 22" , y="7-day average cases")


```
```{r  }
ggplot(data=sb_data, aes(x=delta.days,y=new_deaths )) +
  geom_point()+
  scale_y_continuous( limits=c(-2,40) )+
  scale_x_continuous(limits=c(firstday,maxday))+
  labs( x="days since Jan 22" , y="deaths")

```

Now we'll prune down some of the columns we are keeping and remove any negative numbers (these are due to corrections in the reporting after the fact and sometimes make it appear that people were un-dead)
```{r  }
stan_data <- select(sb_data,new_cases, week_cases ,week_old_cases, two_week_old_cases, three_week_old_cases, four_week_old_cases, new_deaths) %>%
  mutate(new_deaths= new_deaths * (new_deaths>0) ) %>%
  mutate(NC=standardize(new_cases),
         W0=standardize(week_cases),
         W1=standardize(week_old_cases),
         W2=standardize(two_week_old_cases),
         W3=standardize(three_week_old_cases),
         W4=standardize(four_week_old_cases))%>%
  rowid_to_column(var="indy") ## This is the index! I changed the name to 
## account for some error later in the code about duplicate variable names 
```




## Example: Fitting the overall mortality with a Poisson 
```{r  }
m.poiss.overall <- ulam(alist(
   new_deaths ~ dpois(theta),
   log(theta) <- log_theta, 
   ## Think of this ^ as the 'a' in a quap. But it is the log of theta
   log_theta ~ dnorm(0,2)
),data=stan_data , log_lik = TRUE)
```

```{r  }
precis(m.poiss.overall)
```

Redo it with more chains. Here's the trick to keep from re-compiling. But this only works if you want to run the same specific model. This is helpful, but it doesn't keep all of the information stored in an `ulam` model, so be aware of this limitation.
```{r  }
## This code should work, BUT if it doesn't don't worry. Just comment it out and dont run it.
m.poiss.overall.v2 <- stan(fit=m.poiss.overall@cstanfit , data=stan_data , chains=4 , iter=3000, algorithm = "Fixed_param")
```

```{r  }
## Also comment this out if the above chunk doesn't run 
precis(m.poiss.overall.v2)
```

```{r  }
WAIC(m.poiss.overall)
```


How does it compare to our data?

```{r  }
## This line of code is different from the original lab. It should work to get samples 
sim_out_wide<- rethinking::sim(m.poiss.overall,data=stan_data, post = extract.samples(object = m.poiss.overall))


ndays <- nrow(stan_data)

sim_out<-as_tibble(sim_out_wide) %>% 
  gather( "index","deaths",1:(ndays)) %>%
  separate(index,c("V","number"),sep=1) %>%
  mutate(number=as.numeric(number))
```

```{r  }
sim_summarized <- group_by(sim_out,number) %>%
  summarise(deaths_mean=mean(deaths),
            deaths_lower = quantile(deaths,0.05),
            deaths_upper = quantile(deaths,0.95))%>%
  ungroup()
            
```


```{r  }
ggplot(sim_summarized, aes(x=number,y=deaths_mean))+
  geom_point()+
  geom_errorbar( aes(ymin=deaths_lower,ymax=deaths_upper))+
  geom_point(data=stan_data, aes(x=indy,y=new_deaths), color="red")
```


A useful technique for post-processing the samples.
```{r  }
## Another line of code that wouldn't run in the original lab, commented out 
# tmp<-sample(m.poiss.overall@cstanfit) %>% as_tibble()%>%
#   mutate(theta=exp(log_theta) )

## This line of code should work 
tmp<-extract.samples(m.poiss.overall) %>% as_tibble()%>%
  mutate(theta=exp(log_theta) )
  
bayesplot::mcmc_intervals(tmp,pars=c("theta"))
```


### Part 1: Poisson model with the week's cases as a predictor
Create a model where the likelihood model for the daily number of new deaths is Poisson and there is an additive model for the log transformed Poisson parameter. Choose priors based on the range of mean Poisson values that could be produced given the range of the predictor variables. Start with a model where the current week's average Covid cases is the only predictor.

```{r}
## Looking at some of the metrics of NC in the standardized data
mean(stan_data$NC)
which.max(stan_data$NC)
```

As a starter for your first model. This is the formula that we will start off with

$$
\text{new_deaths} ~\mathrm{\sim Poisson(theta)} \\
\mathrm{Log(theta) = \alpha + \beta*new~cases} \\ 
\alpha \sim \mathrm{Normal(0, 2)} \\ 
\beta \sim \mathrm{Normal(0, 0.1)}
$$

Run model and checking precis output:



### Part 2:
Once you have samples for your model, explain how you can have some confidence that the chains are doing a good job of approximating the posterior distribution.

*Look at precis output and answer this question from that* 

### Part 3
Plot the posterior predictions from the model and compare them to the actual data. What do they consistently capture and what do they consistently miss?

*Draw samples from poisson regression: Use the same method as done in example*
```{r}

```


*Plot the posterior predictions using same method as example*
```{r}

```



### Part 4: 
Now build a series of models with prior week's average case numbers as predictors. 
Compare the WAIC values of the different models. What can you conclude? What possible confounds should you consider before making any conclusions?

*A model using this and last weeks cases* 
```{r, message=FALSE}
## All of the next models will follow this scaffold:

## Write ulam model 

## Check precis output 

## Sampling procedure

## Plot posterior predictions

```

*A model with the this weeks, last weeks, and two weeks agos' cases* 
```{r}

```

*A model with the previous variables + three week old cases included * 

```{r}

```


*Finally - last four weeks cases* 

```{r}

```

*Each unit increase in the predictor multiplies the odds of the outcome occurring by exp(coeff).* 


*Compare the WAIC values for each model*
```{r}

```



Similar to the previous question, we need a function that maps the continuous linear model to a strictly positive space. The log link accomplishes this. The inverse of the log link is the exponential, and any value that is exponentiated will be positive.
A logit link would imply a model with a known maximum count. A log-link implies probability between 0-1


## Bonus du jour: Day of the week effect
There are several issues with when deaths are reported. They are reported when the coroner confirms it as a Covid death, which may be delayed from the actual death. They also may not be reported on some days of the week. Can you test for this effect?

```{r}

```

