---
title: "Lab 2"
author: "Stephen R. Proulx, Taom Sakal"
date: "1/23/2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rethinking)
```
# Bayesian Statistical Modeling Winter 2023
## Lab Exercise, Week 2.5
## 1/23/2023

### 3M6
Go back to the situation where we have a flat prior. How many observations would it take to have the 99\% percentile interval be only 1\% wide? We'll assume that the observations are generated by a binomial probability distribution with a probability of water of 0.7. This means that the data are actually generated by the "small world" model we are using to fit the data. 

A reasonable strategy for solving this problem is to automate our code so that we can change the number of observations and determine how wide the 99\% PI is. To do this we will write a function to return the width of the 99\% interval for a specific number of observations. In R, a variable name can have a function assigned to it using the `function` command. 

Below is an outline of the function. Try to fill it in. What the function returns when you run it will be whatever its very last line is.

```{r}
# Make a function that takes in a number of observations N
# and outputs the 99% highest posterior density interval
int.width <- function(N) {
  
  # Set the local function parameters
  # (These parameters live only in this function, and take
  # priority over any global parameters with the same name.)
  p_true <- 0.7
  stepsize <- 0.001
  nsamp <- 1e4

  # Generate the sampled data
  # < write code here >
  W=rbinom(n=1, size=N,prob=p_true)

  # do our grid approximation
  # < write code here >
  post_approx <- tibble(p = seq(from = 0 , to = 1 , by = stepsize)) %>%
    mutate(
      likelihood = dbinom(W , size = N , prob = p),
      prior  = 1,
      raw.posterior = likelihood * prior,
      posterior = raw.posterior / sum(raw.posterior)
    )
  

  # Sample values of p from the posterior distribution
  # < write code here >
   samples <-sample_n(post_approx,posterior,size=nsamp,replace = TRUE) %>%
     select(p)

  # Calculate the 99% interval
  # < write code here >
hpdi_calc=HPDI(samples$p,0.99)

  # Calculate the width of that interval
  # < write code here >

hpdi_witdh=hpdi_calc[[2]]-hpdi_calc[[1]]
(hpdi_witdh)
}
```


Note that the function `int.width` will return different values when you call it because it uses randomly generated data, as well as random samples from the posterior. You can check that it works by calling it on a number of observations.

```{r}
# 99% percentile interval width when there are two observations
int.width(2)

# The width gets smaller as we make more observations
int.width(200)
int.width(2000)
```


We'd like to be able to give this function a list of observation numbers and have it apply itself to each element of that list. For example, *int.width( c(2, 5, 8) )* would be equal to *c( int.width(2), int.width(5), int.width(8) )*. 


To do this we can "vectorize" the function. In R functions can be passed to other functions. The *Vectorize* function takes in a function and returns a version of the function that works on lists like we described.

```{r}
# Make a vectorized version of the function. We'll call it int.width.v
int.width.v <- Vectorize(int.width)  
```

Now *int.width.v( c(2, 5, 8) )* will give us *c( int.width(2), int.width(5), int.width(8) )*

```{r}
int.width(2)
int.width(5)
int.width(8)

int.width( c(2, 5, 8) )  # Not vectorized, only uses first element in vector
int.width.v( c(2, 5, 8) )  # Vectorized, uses all elements and outputs a list
```


Now that we have our function, we can use it repeatedly for different sample sizes (number of observations) to see how big our sample has to be to reduce the interval to 0.1. This will take a little bit of time to run.

```{r}
Nlist <- tibble(Ns = rep(c(10, 20, 50, 100, 250, 500, 750, 1000), each = 100))

Nlist <- mutate(Nlist, PI.width = int.width.v(Ns))
```

Have a look at your list and you will see that it has slightly different values when the function is applied to the same sample size.
```{r}
view(Nlist)
```

Finally we'll plot it and see the PI changes with sample size. We'll put the PI width on a log scale to make it easier to see when it gets below 0.1 (note that $log(0.1,10)=-1$) and put a red horizontal line in.

```{r}
ggplot(data = Nlist, aes(x = Ns, y = log(PI.width, base = 10), group = Ns)) +
  geom_point() +
  geom_jitter() +
  geom_hline(aes(yintercept = log(0.1, base = 10)), color = "red", linetype = "dashed")
```

A little after how many observations do we see that our 99% percentage interval goes below a width of 0.1?

** Type answer here **

(You should get about 500.)

