---
title: "Mar 1, Binomial Regression"
author: "Stephen R. Proulx"
date: "2/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rethinking)
library(bayesplot)
source("../helper.R")
```


# Today's objectives:  
* binomial regression
* Calculating contrasts from posterior parameter distributions
* Specifying models with contrasts built in. 


## The logistic function

The logit transformation maps numbers between 0 and 1 to numbers between -inf and inf. We will talk about mapping from the probabiliy scale to the logit scale, and vice-versa.
```{r}
logit_dat <- tibble( x= seq(from=0,to=1,by=0.001)) %>%
  mutate(y=logit(x))

ggplot(logit_dat, aes(x=x,y=y))+geom_line()
```


The inverse logit transformation maps numbers between between -inf and inf to numbers between 0 and 1. In our additive models we will be combining effects, how do these translate back to the probability scale?
```{r}
inv_logit_dat <- tibble( x= seq(from=-10,to=10,by=0.1)) %>%
  mutate(y=inv_logit(x) , y_add=inv_logit(x+0.5) , y_diff=y_add-y)

ggplot(inv_logit_dat, aes(x=x,y=y))+
  geom_line(color="black")+
  geom_line(aes(x=x,y=y_add) , color="red")

ggplot(inv_logit_dat, aes(x=x,y=y_diff))+
  geom_line(color="black")

```

The effect of our additive model on the probability scale is always dependent on both values that we are combining. This is why McElreath talks about interactions arising even when you don't build them in.   


## Binomial admissions

```{r}
## R code 11.28
library(rethinking)
data(UCBadmit)
d <- UCBadmit %>% 
  as_tibble() %>%
  mutate(gid= (applicant.gender=="male")*1+(applicant.gender=="female")*2,
         dept_id=as.integer( as.factor(dept)))
```


```{r}
## R code 11.29ish
m11.7 <- ulam(
    alist(
        admit ~ dbinom( applications , p ) ,
        logit(p) <- a[gid] ,
        a[gid] ~ dnorm( 0 , 1.5 )
    ) , data=select(d,admit,applications,gid) , chains=4, iter=3000 )
precis( m11.7 , depth=2 )
```


```{r}
## R code 11.30
post <- extract.samples(m11.7) %>% as_tibble()%>%
  mutate(diff_a=a[,1]-a[,2],
         diff_p=inv_logit(a[,1])-inv_logit(a[,2]))

mcmc_intervals(select(post,diff_a),prob_outer = 0.9) 
mcmc_intervals(select(post,diff_p),prob_outer = 0.9) 
```


### Posterior plots


```{r}
## R code 11.31
postcheck( m11.7 )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
    x <- 1 + 2*(i-1)
    y1 <- d$admit[x]/d$applications[x]
    y2 <- d$admit[x+1]/d$applications[x+1]
    lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
    text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
```

These are the mean and the range of the sample values (not just probable interval for the mean of that group), it includes the binomial sampling variance. 

The circls are on a line 
The plusses are not on a line because they take into account how many people applied to a department, so the residual variance.
  - In the dots where there were high amounts of applicants the plusses are going to
  be closer together, because there is lower variance

A model that includes both an effect of gender, and an effect of department. Some departments are harder to get into than others, and some departments have more people admitted than others. 
```{r}
## R code 11.32

m11.8 <- ulam(
    alist(
        admit ~ dbinom( applications , p ) ,
        logit(p) <- a[gid] + delta[dept_id] ,
        a[gid] ~ dnorm( 0 , 1.5 ) ,
        delta[dept_id] ~ dnorm( 0 , 1.5 )
    ) , data=select(d,admit,applications,gid,dept_id) , cores=4, chains=4 , iter=4000, log_lik = TRUE)
precis( m11.8 , depth=2 )
```




```{r}
## R code 11.31
postcheck( m11.8 )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
    x <- 1 + 2*(i-1)
    y1 <- d$admit[x]/d$applications[x]
    y2 <- d$admit[x+1]/d$applications[x+1]
    lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
    text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
```

Now it has the baseline effect of department, but the effect of gender varies across departments. 

### Alternative formulations of the same model.

The alternate model where we force the `a` values to be a difference from an "intercept". In this version, `delta` acts as the intercept for each department, and a is the increase in admission rate (on the logit scale) for women.  
```{r}
## This makes the parameters a bit more interpretable. 
m11.8A <- ulam(
    alist(
        admit ~ dbinom( applications , p ) ,
        logit(p) <- a*(gid-1)  + delta[dept_id] , # 1 and 2 becomes 0 and 1 (indicator)
        a ~ dnorm( 0 , 1.5 ) ,
        delta[dept_id] ~ dnorm( 0 , 1.5 )
    ) , data=select(d,admit,applications,gid,dept_id) , cores=4, chains=4 , iter=4000,log_lik = TRUE) 
```

Compare the intervals and standard deviations of the parameters in the two models, what do you notice?
```{r}
precis(m11.8, depth=2)
precis(m11.8A, depth=2)
```

The difference between a values is about 0.1 for m11.8. For 11.8A, the total difference is about 0.1, and now the deltas are the means for each department and the a is the difference between male and female. 

Now compare the WAIC of the two models.
```{r}
compare(m11.8,m11.8A)
```

These models come up with the same actual predictions for admission probability, they just add together different quantities to get there. Compare this graph to the one we got with model 11.8:
```{r}
postcheck( m11.8A )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
    x <- 1 + 2*(i-1)
    y1 <- d$admit[x]/d$applications[x]
    y2 <- d$admit[x+1]/d$applications[x+1]
    lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
    text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
```

What happens if you tighten the prior on a[gid] in model 11.8? Try it and see how it differs from the version we have already run. Try it and see:








How should we evaluate the results from model 11.8? We need the contrast in a[1] and a[2]. Looking at the overlap of a[1] and a[2] is not enough;
```{r}
post.11.8 <- extract.samples(m11.8) %>% as_tibble()%>%
  mutate(diff_a=a[,2]-a[,1],
         a1=a[,1],
         a2=a[,2])
mcmc_intervals(select(post.11.8,a1,a2)) 

mcmc_intervals(select(post.11.8,diff_a)) +
  xlim(c(-0.1,0.3))

post.11.8A <- extract.samples(m11.8A) %>% as_tibble() %>%
   mutate(diff_a=a)
mcmc_intervals(select(post.11.8A,diff_a))  +
  xlim(c(-0.1,0.3))
```

Now make the graph of the contrasts on the probability scale. Because of the logit link you will have to do it for specific departments.

*This information doesn't tell you everything is fair. It says for other reasons, there are more female applicants to departments with lower admission rates. Why? We dont know its not part of the data. But we could say that there is some bias going on thats causing females to apply to departments with lower admission rates for some reason* 


```{r}
post.11.8 <- extract.samples(m11.8) %>% as_tibble()%>%
  mutate(diff_a=a[,2]-a[,1],
         a1=a[,1],
         a2=a[,2],
         diff_p_1 = inv_logit(delta[,1]+a[,2])-inv_logit(delta[,1]+a[,1]),
          diff_p_2 = inv_logit(delta[,2]+a[,2])-inv_logit(delta[,2]+a[,1]), 
         diff_p_3 = inv_logit(delta[,3]+a[,2])-inv_logit(delta[,3]+a[,1]),
          diff_p_4 = inv_logit(delta[,4]+a[,2])-inv_logit(delta[,4]+a[,1]),
          diff_p_5 = inv_logit(delta[,5]+a[,2])-inv_logit(delta[,5]+a[,1]),
          diff_p_6 = inv_logit(delta[,6]+a[,2])-inv_logit(delta[,6]+a[,1]))


mcmc_intervals(select(post.11.8,diff_p_1,diff_p_2,diff_p_3,diff_p_4,diff_p_5,diff_p_6),prob_outer = 0.9) 
```

This is a plot to show the probable intervals for the difference between the values on the probability scale. Remember in this model the effect of gender is the same in every department; this is a way of observing what the effect of gender, according to the model, is in each department. For the department that has the lowest acceptance rate, p6, a difference in the a value is going to have a very small difference in the p value because its on the lower end of our binomial curve. 

**We can see that this difference doesn't have an effect on the probability scale** 





