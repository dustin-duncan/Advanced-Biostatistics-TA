---
title: "hw_3"
author: "Dustin Duncan"
date: "2024-01-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rethinking)
```

# Bayesian Statistical Modeling Winter 2024
# Homework, Week 3

*When is homework due?*  This assignment is due on Wednesday, 1/31/2023. 


Complete these problems from the end of chapter 4.

## 4E1

Which line below is the likelihood? 

$$
y_i \sim \text{Normal}(\mu, \sigma) \\ ~ \\ 

\mu \sim \text{Normal}(0, 10) \\ ~ \\ 

\sigma \sim \text{Exponential}(1)
$$

The first line in the formula is the likelihood. This is the likelihood because it counts up the relative number of ways different combinations of means and standard deviations can produce an observation. 

## 4E2

There are two parameters in the posterior distribution. Mu and sigma 

## 4E3

$$
Pr(\mu, \sigma | y) = \frac{\prod_i \text{Normal}(y_i|\mu,\sigma)\text{Normal}(\mu|0, 10)\text{Uniform}(\sigma|0, 10)}{\int\int\prod_i\text{Normal}(h_i|\mu,\sigma)\text{Normal}(\mu|0,10)\text{Uniform}(\mu|0,10)d\mu d\sigma}
$$
Damn thats a crazy formula 

## 4E4

In the model definition below, which line is the linear model?

$$
y_i \sim \text{Normal}(\mu, \sigma) \\ ~ \\ 

\mu_i = \alpha +\beta x_i \\ ~ \\ 

\alpha \sim \text{Normal}(0, 10) \\ ~ \\

\beta \sim \text{Normal}(0, 1) \\ ~ \\

\sigma \sim \text{Exponential}(2)
$$

The second line is the linear model.

## 4E5

There are three parameters in the posterior distribution 

## 4M1  

In the model definition below, simulate observed y values from the prior (not the posterior)

The prior predictive simulation is an essential part of your modeling. Once you've chosen priors for h, mu, and sigma, these imply a joint prior distribution of individual heights.

By simulating from this distribution, you can see what your choices imply about observable height.

$$
y_i \sim \text{Normal}(\mu, \sigma) \\ ~ \\ 

\mu \sim \text{Normal}(0, 10) \\ ~ \\ 

\sigma \sim \text{Exponential}(1)
$$

Simulating observed y values from the prior. Every posterior is also potentially a prior for a subsequent analysis, so you can process priors just like posteriors. 

```{r}
set.seed(100)
N <- 100

prior_approx <- tibble(sample_mu = rnorm(N, 0, 10)) %>% 
  mutate(sample_sigma = rexp(N, 1),
         prior_y = rnorm(N, sample_mu, sample_sigma))

set.seed(100)

sample_mu <- rnorm(N, 0, 10)

sample_sigma <- rexp(N, 1)

prior_y <- rnorm(N, sample_mu, sample_sigma)

ggplot(data = prior_approx, aes(x = prior_y, y = after_stat(density))) + 
  geom_histogram(bins = 30, alpha = 0.75) + 
  geom_density(data = prior_approx, aes(x = prior_y), alpha = 1, color = "red")

dens(prior_y)
```


## 4M2  

Translate the model above into a quap formula:
```{r}
m1 <- quap(
  alist(
    y ~ dnorm(mu, sigma),
    mu ~ dnorm(0, 10),
    sigma ~ dexp(1)
  )
)
```


## 4M3

$$
y_i \sim \text{Normal}(\mu, \sigma) \\ ~ \\ 

\mu = \alpha + \beta x_i \\ ~ \\ 

\alpha \sim \text{Normal}(0, 10) \\ ~ \\

\beta \sim \text{Uniform}(0, 1) \\ ~ \\

\sigma \sim \text{Exponential}(1)
$$

